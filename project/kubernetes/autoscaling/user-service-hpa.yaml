# Horizontal Pod Autoscaler (HPA) for User Service
#
# WHAT THIS DOES:
# HPA automatically increases or decreases the number of pod replicas based on
# observed metrics like CPU usage, memory usage, or custom metrics. This ensures
# your application can handle varying loads without manual intervention.
#
# KEY CONCEPTS:
# - minReplicas: Minimum number of pods to always keep running
# - maxReplicas: Maximum number of pods that can be created
# - targetCPUUtilizationPercentage: Target CPU usage (HPA scales to maintain this)
# - scaleDown/scaleUp: Policies that control how quickly scaling happens
#
# HOW IT WORKS:
# 1. HPA continuously monitors metrics (CPU, memory, custom metrics)
# 2. If average metric exceeds target, it increases replicas
# 3. If average metric is below target, it decreases replicas
# 4. Scaling decisions respect min/max replica limits
#
# WHY WE NEED IT:
# Traffic to web services varies throughout the day. HPA ensures you have enough
# resources during peak times and reduces costs during low-traffic periods.

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
  namespace: default
spec:
  # Which deployment to scale
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service-deployment
  
  # Minimum and maximum number of replicas
  minReplicas: 2   # Always keep at least 2 pods for high availability
  maxReplicas: 10  # Don't create more than 10 pods (cost control)
  
  # Metrics to base scaling decisions on
  metrics:
  # Scale based on CPU utilization
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # Target 70% CPU usage
        # If average CPU > 70%, scale up
        # If average CPU < 70%, scale down
  
  # Scale based on memory utilization
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # Target 80% memory usage
  
  # Optional: Scale based on custom metrics (e.g., requests per second)
  # This requires a metrics adapter (like Prometheus Adapter)
  # - type: Pods
  #   pods:
  #     metric:
  #       name: http_requests_per_second
  #     target:
  #       type: AverageValue
  #       averageValue: "100"  # Scale when average RPS > 100
  
  # Scaling behavior - controls how quickly scaling happens
  behavior:
    # Behavior when scaling up (increasing replicas)
    scaleUp:
      # Stabilization window - wait this long before scaling up again
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100  # Increase by up to 100% of current replicas
        periodSeconds: 15  # Every 15 seconds
      - type: Pods
        value: 2    # Or add 2 pods at a time
        periodSeconds: 15
      # Use the policy that results in the most pods
      selectPolicy: Max
    
    # Behavior when scaling down (decreasing replicas)
    scaleDown:
      # Wait longer before scaling down (prevents thrashing)
      stabilizationWindowSeconds: 300  # 5 minutes
      policies:
      - type: Percent
        value: 50   # Decrease by up to 50% of current replicas
        periodSeconds: 60  # Every 60 seconds
      # Use the policy that results in the fewest pods
      selectPolicy: Min

